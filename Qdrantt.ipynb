{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load a pre-trained ResNet-101 model\n",
    "model = models.resnet101(pretrained=True)\n",
    "# Remove the last fully connected layer (classifier)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "# Transfer the model to the GPU\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(img_path, model, device):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_t = preprocess(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    # Transfer the tensor to the GPU\n",
    "    batch_t = batch_t.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(batch_t)\n",
    "        features = torch.flatten(features, 1)\n",
    "    return features.cpu().numpy()  # Move the features back to CPU for further processing or storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from a folder\n",
    "folder_path = 'Y:\\SIH-main\\sih\\sih dataset-labels\\sih dataset\\prescription'  # Replace with the path to your folder\n",
    "image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# Extract features for all images in the folder\n",
    "features_list = [extract_features(image_path, model, device) for image_path in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "# Assume Qdrant is running locally\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection\n",
    "client.recreate_collection(\n",
    "    collection_name=\"my_collection\",\n",
    "    vectors_config=VectorParams(size=2048, distance=Distance.COSINE),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http.models import PointStruct\n",
    "import numpy as np\n",
    "\n",
    "# Assume `features_list` is a list of numpy arrays with your extracted features\n",
    "# and `image_paths` is a list of corresponding image paths\n",
    "\n",
    "# Store the features in Qdrant\n",
    "def to_float_list(feature_vector):\n",
    "    # Convert to numpy array if not already\n",
    "    if not isinstance(feature_vector, np.ndarray):\n",
    "        feature_vector = np.array(feature_vector)\n",
    "    # Ensure the dtype is float32\n",
    "    if feature_vector.dtype != np.float32:\n",
    "        feature_vector = feature_vector.astype(np.float32)\n",
    "    # Flatten the array and convert to list\n",
    "    return feature_vector.ravel().tolist()\n",
    "\n",
    "# Store the features in Qdrant\n",
    "client.upsert(\n",
    "    collection_name=\"my_collection\",\n",
    "    points=[\n",
    "        PointStruct(\n",
    "            id=i,  # Convert ID to a string\n",
    "            vector=to_float_list(feature),  # Convert feature vector to a list of floats\n",
    "            payload={\"image_path\": image_paths[i]}\n",
    "        )\n",
    "        for i, feature in enumerate(features_list)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from the input image\n",
    "input_image_path = 'Y:\\SIH-main\\sih\\sih dataset-labels\\sih dataset\\prescription\\\\ap10.png'  # Replace with your input image path\n",
    "input_features = extract_features(input_image_path, model,device)\n",
    "\n",
    "# Search for similar images in Qdrant\n",
    "search_result = client.search(\n",
    "    collection_name='my_collection',\n",
    "    query_vector=input_features.ravel().tolist(),\n",
    "    limit=5  # Number of similar images to retrieve\n",
    ")\n",
    "\n",
    "# Extract the paths of the most similar images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Score                                         Image Path\n",
      "ID                                                             \n",
      "2   1.000000  Y:\\SIH-main\\sih\\sih dataset-labels\\sih dataset...\n",
      "8   0.959605  Y:\\SIH-main\\sih\\sih dataset-labels\\sih dataset...\n",
      "10  0.948138  Y:\\SIH-main\\sih\\sih dataset-labels\\sih dataset...\n",
      "9   0.910915  Y:\\SIH-main\\sih\\sih dataset-labels\\sih dataset...\n",
      "5   0.904244  Y:\\SIH-main\\sih\\sih dataset-labels\\sih dataset...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_search_results(search_results):\n",
    "    # Create a list to store the parsed search result data\n",
    "    data = []\n",
    "\n",
    "    # Iterate over each result and extract the relevant information\n",
    "    for result in search_results:\n",
    "        data.append({\n",
    "            'ID': result.id,\n",
    "            'Score': result.score,\n",
    "            'Image Path': result.payload['image_path']\n",
    "        })\n",
    "\n",
    "    # Create a pandas DataFrame from the data list\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Set the ID column as the index of the DataFrame\n",
    "    df.set_index('ID', inplace=True)\n",
    "\n",
    "    # Display the DataFrame as a table\n",
    "    print(df)\n",
    "\n",
    "display_search_results(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=2, version=0, score=1.0000000034742436, payload={'image_path': 'Y:\\\\SIH-main\\\\sih\\\\sih dataset-labels\\\\sih dataset\\\\prescription\\\\ap10.png'}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=8, version=0, score=0.959605218278751, payload={'image_path': 'Y:\\\\SIH-main\\\\sih\\\\sih dataset-labels\\\\sih dataset\\\\prescription\\\\ap7.png'}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=10, version=0, score=0.9481375430706294, payload={'image_path': 'Y:\\\\SIH-main\\\\sih\\\\sih dataset-labels\\\\sih dataset\\\\prescription\\\\ap9.png'}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=9, version=0, score=0.9109149692319604, payload={'image_path': 'Y:\\\\SIH-main\\\\sih\\\\sih dataset-labels\\\\sih dataset\\\\prescription\\\\ap8.png'}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=5, version=0, score=0.9042442729065638, payload={'image_path': 'Y:\\\\SIH-main\\\\sih\\\\sih dataset-labels\\\\sih dataset\\\\prescription\\\\ap4.png'}, vector=None, shard_key=None)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
